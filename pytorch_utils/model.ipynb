{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from pytorch_utils.data_pipeline import TSData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loder for a sequential model\n",
    "\n",
    "* For the training loader, we use a window size of 100 time steps from the range 1980-01-01 to 2000-12-31\n",
    "* For the validation loader, we use the entire sequence 2001-01-01 to 2020-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr('./simple_sm_model/data/era5_40N6W.zarr').load()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    TSData(ds=ds, features=['et', 'tp'], targets='sm', time_slice=slice('1980', '2000')),\n",
    "    batch_size=50,\n",
    "    shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    TSData(ds=ds, features=['et', 'tp'], targets='sm', time_slice=slice('2001', '2020'), norm_stats=train_loader.dataset.norm_stats),\n",
    "    batch_size=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can iterate the data in batches of size 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 7671, 2]) torch.Size([50, 7671, 1])\n",
      "torch.Size([50, 7671, 2]) torch.Size([50, 7671, 1])\n",
      "torch.Size([50, 7671, 2]) torch.Size([50, 7671, 1])\n",
      "torch.Size([50, 7671, 2]) torch.Size([50, 7671, 1])\n",
      "torch.Size([50, 7671, 2]) torch.Size([50, 7671, 1])\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(train_loader):\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "    if i > 3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_feature: int,\n",
    "            num_targets: int=1,\n",
    "            num_hidden: int=8,\n",
    "            num_layers: int=2,\n",
    "            dropout: float = 0.0,\n",
    "            activation: nn.Module = nn.Sigmoid,\n",
    "            output_activation: nn.Module = nn.Identity,\n",
    "            learning_rate: float = 0.001,\n",
    "            weight_decay: float = 0.0) -> None:\n",
    "        \"\"\"A fully connected feed-forward model.\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        num_features: int\n",
    "            The number of input features.\n",
    "        num_targets: int (default is 1)\n",
    "            The number of targets.\n",
    "        num_hidden: int (default is 8)\n",
    "            The number of hidden nodes per layer.\n",
    "        num_layers: int (default is 2)\n",
    "            The number of hidden nodes.\n",
    "        dropout: float (default is 0.0)\n",
    "            The dropout used in all hidden layers.\n",
    "        activation: nn.Module (default is nn.Sigmoid)\n",
    "            The activation function.\n",
    "        output_activation: nn.Module (default is nn.Identity)\n",
    "            The output activation function, default is nn.Identity and does not transform the output.\n",
    "        learning_rate: float (default is 0.001):\n",
    "            The learning rate.\n",
    "        weight_decay: float (default is 0.0)\n",
    "            The weight decay (L2 regularization).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        layers = OrderedDict()\n",
    "        in_sizes = [num_feature] + [num_hidden] * num_layers\n",
    "        out_sizes = [num_hidden] * num_layers + [num_targets]\n",
    "\n",
    "        for i, (nin, nout) in enumerate(zip(in_sizes, out_sizes)):\n",
    "            is_input_layer = i == 0\n",
    "            is_output_layer = i == num_layers\n",
    "\n",
    "            layers.update({f'linear{i}': nn.Linear(in_features=nin, out_features=nout)})\n",
    "\n",
    "            if not is_input_layer and not is_output_layer:\n",
    "                layers.update({f'dropout{i}': nn.Dropout(dropout)})\n",
    "\n",
    "            if is_output_layer:\n",
    "                layers.update({f'activation{i}': output_activation()})\n",
    "            else:\n",
    "                layers.update({f'activation{i}': activation()})\n",
    "\n",
    "        self.model = nn.Sequential(layers)\n",
    "\n",
    "        self.optimizer = self.get_optimizer(self.model.parameters(), learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_epoch(self, train_loader: torch.utils.data.DataLoader) -> Tensor:\n",
    "        self.train()\n",
    "\n",
    "        loss_sum = torch.zeros(1)\n",
    "        loss_counter = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            y_hat = self(x)\n",
    "            loss = self.loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            loss_counter += 1\n",
    "        \n",
    "        return (loss_sum / loss_counter).item()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval_epoch(self, valid_loader: torch.utils.data.DataLoader) -> Tensor:\n",
    "        self.eval()\n",
    "\n",
    "        loss_sum = torch.zeros(1)\n",
    "        loss_counter = 0\n",
    "\n",
    "        for x, y in valid_loader:\n",
    "\n",
    "            y_hat = self(x)\n",
    "            loss = self.loss_fn(y_hat, y)\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        loss_counter += 1\n",
    "\n",
    "        return (loss_sum / loss_counter).item()\n",
    "\n",
    "    def tune(self, num_epochs: int, train_loader: torch.utils.data.DataLoader, valid_loader: torch.utils.data.DataLoader) -> None:\n",
    "        self.train_losses = np.zeros(num_epochs)\n",
    "        self.valid_losses = np.zeros(num_epochs)\n",
    "\n",
    "        train_loss = -1\n",
    "        valid_loss = -1\n",
    "        pbar = tqdm(range(num_epochs))\n",
    "        for epoch in pbar:\n",
    "            pbar.set_description(f'train loss: {train_loss}, valid loss: {valid_loss}')\n",
    "\n",
    "            train_loss = self.train_epoch(train_loader=train_loader)\n",
    "            valid_loss = self.eval_epoch(valid_loader=valid_loader)\n",
    "\n",
    "            self.train_losses[epoch] = train_loss\n",
    "            self.valid_losses[epoch] = valid_loss\n",
    "\n",
    "    def get_optimizer(self, params: torch.ParameterDict, learning_rate: float = 0.001, weight_decay: float = 0.0) -> torch.optim.Optimizer:\n",
    "        return torch.optim.AdamW(params, lr=learning_rate, weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN(num_feature=2, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.5468218326568604, valid loss: 3.3669896125793457: 100%|██████████| 10/10 [05:32<00:00, 33.28s/it]\n"
     ]
    }
   ],
   "source": [
    "model.tune(num_epochs=10, train_loader=train_loader, valid_loader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x146c9afd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.train_losses, label='training', color='tab:orange')\n",
    "plt.plot(model.valid_losses, label='validation', color='tab:red')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mse loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92aae6b20a6f5ebf89ae3e9c40883b7c8e98dd47a94d1bbbc976466dcff59ecb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('attr_hack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
